# -*- coding: utf-8 -*-
"""alexnet1sch.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1EO_bXVWWXXMeH7wGje8W0ioL0I5MptfG
"""

import os
import keras
import numpy as np
import pandas as pd
import cv2
import tensorflow
from keras.layers import Input, Dense, Flatten, Conv2D, MaxPool2D, ZeroPadding2D
from sklearn.preprocessing import LabelEncoder , OneHotEncoder
from sklearn.utils import shuffle
from sklearn.model_selection import train_test_split
from tensorflow.keras.utils import to_categorical
import matplotlib.pyplot as plt

dataset_path = os.listdir('/content/drive/MyDrive/schzrinopiadata')
emotion_types = os.listdir('/content/drive/MyDrive/schzrinopiadata')
print (emotion_types)  #what kinds of emotions are in this dataset

print("Types of emotions found: ", len(dataset_path))

emotions = []

for item in emotion_types:
 # Get all the file names
 all_emotions = os.listdir('/content/drive/MyDrive/schzrinopiadata' + '/' +item)
 #print(all_emotion)

 # Add them to the list
 for emotion in all_emotions:
    emotions.append((item, str('emotions_dataset' + '/' +item) + '/' + emotion))
    print(emotions)

# Build a dataframe        
emotions_df = pd.DataFrame(data=emotions, columns=['game no.', 'image'])
print(emotions_df.head())
print(emotions_df.tail())

# Let's check how many samples for each category are present
print("Total number of emotions in the dataset: ", len(emotions_df))

emotion_count = emotions_df['game no.'].value_counts()

print("emotions in each category: ")
print(emotion_count)

path = '/content/drive/MyDrive/schzrinopiadata'


im_size = 227
images = []
labels = []

for i in emotion_types:
    data_path = path + '/'+str(i)  
    filenames = [i for i in os.listdir(data_path) ]
   
    for f in filenames:
        img = cv2.imread(data_path + '/' + f)
        img = cv2.resize(img, (im_size, im_size))
        images.append(img)
        labels.append(i)

images = np.array(images)

images = images.astype('float32') / 255.0
images.shape

y = emotions_df['game no.'].values
# #print(y[:5])

y_labelencoder = LabelEncoder ()
y = y_labelencoder.fit_transform (y)
y = to_categorical(y, 2)
# print (y.shape)
y[:5]

images, y = shuffle(images,y, random_state=1)

train_x, test_x, train_y, test_y = train_test_split(images, y, test_size=0.20, random_state=415)

#inpect the shape of the training and testing.
print(train_x.shape)
print(train_y.shape)
print(test_x.shape)
print(test_y.shape)

train_y.shape, test_y.shape

model = keras.Sequential()

model.add(Input(shape = (227, 227, 3)))

model.add(Conv2D(filters = 96, kernel_size = (11, 11), strides = 4))

model.add(MaxPool2D(pool_size = 3, strides = 2))

model.add(Conv2D(filters = 256, kernel_size = 5))
model.add(ZeroPadding2D(padding = 2))

model.add(MaxPool2D(pool_size = 3, strides = 2))

model.add(Conv2D(filters = 384, kernel_size = 3))
model.add(ZeroPadding2D(padding = 1))

model.add(Conv2D(filters = 384, kernel_size = 3))
model.add(ZeroPadding2D(padding = 1))

model.add(Conv2D(filters = 256, kernel_size = 3))
model.add(ZeroPadding2D(padding = 1))

model.add(MaxPool2D(pool_size = 3, strides = 2))
model.add(Flatten())

model.add(Dense(units = 4096, activation = 'relu'))
model.add(Dense(units = 4096, activation = 'relu'))
# model.add(Dense(units = 1000, activation = 'relu'))
model.add(Dense(units = 2, activation = 'softmax'))

# model.summary()

model.compile(optimizer = tensorflow.keras.optimizers.Adam(learning_rate = 0.0001), loss = 'BinaryCrossentropy', metrics = ['accuracy'])
r=model.fit(train_x, train_y, epochs = 50, batch_size = 64,validation_data = (test_x, test_y))

# accuracies
fig, ax1 = plt.subplots(nrows=1)
plt.plot(r.history['accuracy'], label='train acc')
plt.plot(r.history['val_accuracy'], label='test acc')
plt.xlabel('No. of Epochs')
plt.ylabel('accuracy')
plt.legend()
fig.savefig('plot.png',dpi = 2000)

# loss
fig, ax1 = plt.subplots(nrows=1)
plt.plot(r.history['loss'], label='train loss')
plt.plot(r.history['val_loss'], label='test loss')
plt.xlabel('no. of epochs')
plt.ylabel('loss')
plt.legend()
fig.savefig('plot_1.png',dpi = 2000)

predict_x=model.predict(test_x) 
classes_x=np.argmax(predict_x,axis=1)
classes_y=np.argmax(test_y,axis=1)
print(classes_x)
print(classes_y)

from sklearn.metrics import precision_score,recall_score,f1_score

precision= precision_score(classes_y,classes_x)
print('precision is %0.3f'%precision)

recall= recall_score(classes_y,classes_x)
print('recall is %0.3f'%recall)

f1= f1_score(classes_y,classes_x)
print('f1 is %0.3f'%f1)

from sklearn.metrics import confusion_matrix
matrix = confusion_matrix(classes_y, classes_x)
print(matrix)

